{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCNN_Kente_Cloth_Experiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlGudPGdzLng",
        "outputId": "666cabc4-540d-4486-c249-85ff447da2e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Google Colab wants to use newer Keras 2, Tensorflow 2 but this\n",
        "# notebook was written against older version, with the experiments\n",
        "# run in 8/2018 (per author)\n",
        "\n",
        "# This suggests Tensorflow v.1.9.0 (7/18) - v.1.10.0 (8/7), v.1.10.1 (8/23)\n",
        "# This suggests Keras 2.2.2 (7/28/18) - 2.2.3 10/1/18\n",
        "\n",
        "# For available Tensorflow versions, see: https://www.tensorflow.org/versions\n",
        "# For a list of compatiable Tensorflow/Keras environments see: https://docs.floydhub.com/guides/environments/\n",
        "\n",
        "# Let's try to install \n",
        "%tensorflow_version 1.x . # helps the instance configure right CUDA, GPU libraries\n",
        "!pip install tensorflow==1.10.1\n",
        "\n",
        "import tensorflow\n",
        "import platform\n",
        "print(\"Using Python: \", platform.python_version())\n",
        "print(\"Using Tensorflow: \", tensorflow.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "print(\"Using Keras: \", keras.__version__)  # note 2.2.0-3 but let's see if this works"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.x . # helps the instance configure right CUDA, GPU libraries`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: tensorflow==1.10.1 in /usr/local/lib/python3.6/dist-packages (1.10.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (0.9.0)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (39.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (1.12.0)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (1.14.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (0.34.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (3.10.0)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (1.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1) (0.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.1) (0.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.1) (3.1.1)\n",
            "Using Python:  3.6.9\n",
            "Using Tensorflow:  1.10.1\n",
            "Using Keras:  2.1.6-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_cviHGDL03Gs",
        "outputId": "6a4aedf0-1619-49af-ef95-0e834389ef74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#  Set up project wide related configration, libraries, mount data directory\n",
        "from google.colab import drive\n",
        "import platform\n",
        "import sys,os\n",
        "import numpy as np\n",
        "\n",
        "!pip install fuel\n",
        "!pip install picklable_itertools\n",
        "%matplotlib inline\n",
        "\n",
        "PROJECT_DIR = \"/content/drive/My Drive/Dr Eglash/Kente_Cloth_Authentication/oc-nn\"\n",
        "\n",
        "sys.path.append(PROJECT_DIR)\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)  # <-- requires user interaction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fuel in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fuel) (1.14.5)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from fuel) (3.38.0)\n",
            "Requirement already satisfied: picklable-itertools in /usr/local/lib/python3.6/dist-packages (from fuel) (0.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fuel) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from fuel) (2.8.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fuel) (6.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fuel) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fuel) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fuel) (1.12.0)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from fuel) (3.4.4)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fuel) (17.0.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->fuel) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fuel) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fuel) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fuel) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fuel) (3.0.4)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->fuel) (2.7.1)\n",
            "Requirement already satisfied: picklable_itertools in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from picklable_itertools) (1.12.0)\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MCXJ2NH92akD",
        "outputId": "eb92bb75-2d26-4346-aa10-e86af19f1cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "# Kick off train, test loop for one class nueral net with one class loss\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from src.models.config import Configuration as Cfg\n",
        "from src.models.OneClass_SVDD import OneClass_SVDD\n",
        "\n",
        "from src.data import __local__\n",
        "print(__local__.implemented_datasets)\n",
        "\n",
        "# I don't think I need this\n",
        "#import os\n",
        "#os.chdir(PROJECT_DIR)\n",
        "\n",
        "DATASET = \"kente\"\n",
        "IMG_DIM= 1024\n",
        "IMG_HGT =32\n",
        "IMG_WDT=32\n",
        "IMG_CHANNEL=3\n",
        "HIDDEN_LAYER_SIZE= 32\n",
        "MODEL_SAVE_PATH = PROJECT_DIR + \"/models/KENTE/OC_NN/\"\n",
        "REPORT_SAVE_PATH = PROJECT_DIR + \"/reports/figures/KENTE/OC_NN/\"\n",
        "PRETRAINED_WT_PATH = \"\"\n",
        "LOSS_FUNCTION = \"ONE_CLASS_NEURAL_NETWORK\"\n",
        "\n",
        "RANDOM_SEED = [42,56,81,67,33,25,90,77,15,11]\n",
        "RANDOM_SEED = [42]  # for inital test\n",
        "AUC = []\n",
        "\n",
        "if 'ocnn' in locals():\n",
        "  del ocnn\n",
        "\n",
        "for seed in RANDOM_SEED:\n",
        "  #import pdb\n",
        "  #pdb.set_trace()\n",
        "  Cfg.seed = seed\n",
        "  ocnn = OneClass_SVDD(DATASET,LOSS_FUNCTION,IMG_DIM, HIDDEN_LAYER_SIZE, IMG_HGT, IMG_WDT,IMG_CHANNEL, MODEL_SAVE_PATH, REPORT_SAVE_PATH,PRETRAINED_WT_PATH,seed)\n",
        "  \n",
        "  print(\"[INFO:] Testing with known anomalies\")\n",
        "  ocnn.fit()\n",
        "  print(\"==============PREDICTING THE LABELS ==============================\")\n",
        "  auc_score = ocnn.predict()\n",
        "  AUC.append(auc_score)\n",
        "\n",
        "print(\"===========TRAINING AND PREDICTING WITH OCSVDD============================\")\n",
        "print(\"AUROC computed \", AUC)\n",
        "auc_roc_mean = np.mean(np.asarray(AUC))\n",
        "auc_roc_std = np.std(np.asarray(AUC))\n",
        "print (\"AUROC =====\", auc_roc_mean ,\"+/-\",auc_roc_std)\n",
        "print(\"========================================================================\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('mnist', 'cifar10', 'gtsrb', 'kente')\n",
            "OneClass_SVDD.RESULT_PATH: /content/drive/My Drive/Dr Eglash/Kente_Cloth_Authentication/oc-nn/reports/figures/KENTE/OC_NN/\n",
            "Inside the MNIST_DataLoader RCAE.RESULT_PATH: /content/drive/My Drive/Dr Eglash/Kente_Cloth_Authentication/oc-nn/reports/figures/MNIST/RCAE/\n",
            "[INFO: ] Loading data...\n",
            "[INFO:] The  label  of normal points are  0\n",
            "[INFO:] Random Seed used is   42\n",
            "[INFO: ] Data loaded.\n",
            "[INFO:] Assertions of memory muted\n",
            "Inside the MNIST_DataLoader RCAE.RESULT_PATH: /content/drive/My Drive/Dr Eglash/Kente_Cloth_Authentication/oc-nn/reports/figures/MNIST/RCAE/\n",
            "[INFO: ] Loading data...\n",
            "[INFO:] The  label  of normal points are  0\n",
            "[INFO:] Random Seed used is   42\n",
            "[INFO: ] Data loaded.\n",
            "[INFO:] Testing with ALL other  DIGITs  as anomalies\n",
            "[INFO: ] Shape of One Class Input Data used in training (5975, 28, 28, 1)\n",
            "[INFO: ] Shape of (Positive) One Class Input Data used in training (5916, 28, 28, 1)\n",
            "[INFO: ] Shape of (Negative) One Class Input Data used in training (59, 28, 28, 1)\n",
            "[ INFO ] : The shape of Xtrain is  (4986, 28, 28, 1)\n",
            "Learning dictionary for weight initialization...\n",
            "[dict_learning] .+++++++.+++......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Dictionary learned.\n",
            "[INFO:] The shape of X used to train CAE (4986, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-16046aa34ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO:] Testing with ALL other  DIGITs  as anomalies\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mocnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==============PREDICTING THE LABELS ==============================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Dr Eglash/Kente_Cloth_Authentication/oc-nn/src/models/OneClass_SVDD.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1704\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_oneClass_trainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m             \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mcae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrain_cae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m             \u001b[0;31m# Create the SVDD network architecture and load pre-trained ae network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             \u001b[0;31m# Initialize center c as the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Dr Eglash/Kente_Cloth_Authentication/oc-nn/src/models/OneClass_SVDD.py\u001b[0m in \u001b[0;36mpretrain_cae\u001b[0;34m(self, solver, lr, n_epochs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m                 verbose=0)\n\u001b[0m\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;31m# Save model and its weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}